{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LeNet using MNIST and Devito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import joey as ml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from devito import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.set_log_noperf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lenet():\n",
    "    # Six 3x3 filters, activation RELU\n",
    "    layer1 = ml.Conv(kernel_size=(6, 3, 3),\n",
    "                     input_size=(batch_size, 1, 32, 32),\n",
    "                     activation=ml.activation.ReLU(),\n",
    "                     generate_code=False)\n",
    "    # Max 2x2 subsampling\n",
    "    layer2 = ml.MaxPooling(kernel_size=(2, 2),\n",
    "                           input_size=(batch_size, 6, 30, 30),\n",
    "                           stride=(2, 2),\n",
    "                           generate_code=False)\n",
    "    # Sixteen 3x3 filters, activation RELU\n",
    "    layer3 = ml.Conv(kernel_size=(16, 3, 3),\n",
    "                     input_size=(batch_size, 6, 15, 15),\n",
    "                     activation=ml.activation.ReLU(),\n",
    "                     generate_code=False)\n",
    "    # Max 2x2 subsampling\n",
    "    layer4 = ml.MaxPooling(kernel_size=(2, 2),\n",
    "                           input_size=(batch_size, 16, 13, 13),\n",
    "                           stride=(2, 2),\n",
    "                           strict_stride_check=False,\n",
    "                           generate_code=False)\n",
    "    # Full connection (16 * 6 * 6 -> 120), activation RELU\n",
    "    layer5 = ml.FullyConnected(weight_size=(120, 576),\n",
    "                               input_size=(576, batch_size),\n",
    "                               activation=ml.activation.ReLU(),\n",
    "                               generate_code=False)\n",
    "    # Full connection (120 -> 84), activation RELU\n",
    "    layer6 = ml.FullyConnected(weight_size=(84, 120),\n",
    "                               input_size=(120, batch_size),\n",
    "                               activation=ml.activation.ReLU(),\n",
    "                               generate_code=False)\n",
    "    # Full connection (84 -> 10), output layer\n",
    "    layer7 = ml.FullyConnectedSoftmax(weight_size=(10, 84),\n",
    "                                      input_size=(84, batch_size),\n",
    "                                      generate_code=False)\n",
    "    # Flattening layer necessary between layer 4 and 5\n",
    "    layer_flat = ml.Flat(input_size=(batch_size, 16, 6, 6),\n",
    "                         generate_code=False)\n",
    "    \n",
    "    layers = [layer1, layer2, layer3, layer4,\n",
    "              layer_flat, layer5, layer6, layer7]\n",
    "    \n",
    "    return (ml.Net(layers), layers)\n",
    "\n",
    "def relu(x):\n",
    "    return Max(0, x)\n",
    "\n",
    "def maximum(lst):\n",
    "    return Max(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, input_data, expected_results, pytorch_optimizer):\n",
    "    outputs = net.forward(input_data)\n",
    "    \n",
    "    def loss_grad(layer, b):\n",
    "        gradients = []\n",
    "    \n",
    "        for i in range(10):\n",
    "            result = layer.result.data[i, b]\n",
    "            if i == expected_results[b]:\n",
    "                result -= 1\n",
    "            gradients.append(result)\n",
    "    \n",
    "        return gradients\n",
    "    \n",
    "    net.backward(loss_grad, pytorch_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((32, 32)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(0.5, 0.5)])\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksymilian/Desktop/UROP/devito/devito/types/grid.py:206: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  spacing = (np.array(self.extent) / (np.array(self.shape) - 1)).astype(self.dtype)\n"
     ]
    }
   ],
   "source": [
    "devito_net, devito_layers = create_lenet()\n",
    "optimizer = optim.SGD(devito_net.pytorch_parameters, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_kernel = torch.tensor(devito_layers[0].kernel.data)\n",
    "layer1_bias = torch.tensor(devito_layers[0].bias.data)\n",
    "layer3_kernel = torch.tensor(devito_layers[2].kernel.data)\n",
    "layer3_bias = torch.tensor(devito_layers[2].bias.data)\n",
    "layer5_kernel = torch.tensor(devito_layers[5].kernel.data)\n",
    "layer5_bias = torch.tensor(devito_layers[5].bias.data)\n",
    "layer6_kernel = torch.tensor(devito_layers[6].kernel.data)\n",
    "layer6_bias = torch.tensor(devito_layers[6].bias.data)\n",
    "layer7_kernel = torch.tensor(devito_layers[7].kernel.data)\n",
    "layer7_bias = torch.tensor(devito_layers[7].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    images, labels = data\n",
    "    images.double()\n",
    "    \n",
    "    train(devito_net, images, labels, optimizer)\n",
    "    \n",
    "    if i == iterations - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.double()\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.conv1.weight[:] = layer1_kernel\n",
    "    net.conv1.bias[:] = layer1_bias\n",
    "    net.conv2.weight[:] = layer3_kernel\n",
    "    net.conv2.bias[:] = layer3_bias\n",
    "    net.fc1.weight[:] = layer5_kernel\n",
    "    net.fc1.bias[:] = layer5_bias\n",
    "    net.fc2.weight[:] = layer6_kernel\n",
    "    net.fc2.bias[:] = layer6_bias\n",
    "    net.fc3.weight[:] = layer7_kernel\n",
    "    net.fc3.bias[:] = layer7_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    images, labels = data\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(images.double())\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i == iterations - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers[0] maximum relative error: 1.3407192418942228e-14\n",
      "layers[1] maximum relative error: 2.5473953487847755e-12\n",
      "layers[2] maximum relative error: 1.0280702754555613e-12\n",
      "layers[3] maximum relative error: 8.103937510501394e-13\n",
      "layers[4] maximum relative error: 1.3993901259386298e-13\n",
      "\n",
      "Maximum relative error is in layers[1]: 2.5473953487847755e-12\n"
     ]
    }
   ],
   "source": [
    "layers = [devito_layers[0], devito_layers[2], devito_layers[5], devito_layers[6], devito_layers[7]]\n",
    "pytorch_layers = [net.conv1, net.conv2, net.fc1, net.fc2, net.fc3]\n",
    "\n",
    "max_error = 0\n",
    "index = -1\n",
    "\n",
    "for i in range(5):\n",
    "    kernel = layers[i].kernel.data\n",
    "    pytorch_kernel = pytorch_layers[i].weight.detach().numpy()\n",
    "    \n",
    "    kernel_error = abs(kernel - pytorch_kernel) / abs(pytorch_kernel)\n",
    "    \n",
    "    bias = layers[i].bias.data\n",
    "    pytorch_bias = pytorch_layers[i].bias.detach().numpy()\n",
    "    \n",
    "    bias_error = abs(bias - pytorch_bias) / abs(pytorch_bias)\n",
    "    \n",
    "    error = max(np.nanmax(kernel_error), np.nanmax(bias_error))\n",
    "    print('layers[' + str(i) + '] maximum relative error: ' + str(error))\n",
    "    \n",
    "    if error > max_error:\n",
    "        max_error = error\n",
    "        index = i\n",
    "\n",
    "print()\n",
    "print('Maximum relative error is in layers[' + str(index) + ']: ' + str(max_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
